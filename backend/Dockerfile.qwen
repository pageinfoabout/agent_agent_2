# Use CUDA runtime with Python 3.11 (PyTorch images include Python 3.11)
FROM pytorch/pytorch:2.9.1-cuda13.0-cudnn8-runtime

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && \
    apt-get install -y git sox libsox-fmt-all && \
    rm -rf /var/lib/apt/lists/*

# Copy backend files (adjust build context to ./backend)
COPY . /app

# Install PyTorch + torchaudio (already included in PyTorch image, but ensures matching version)
RUN pip install --no-cache-dir torch==2.9.1 torchaudio==2.9.1 --index-url https://download.pytorch.org/whl/cu130

# Install Flash Attention wheel for Python 3.11
RUN pip install --no-cache-dir \
    https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.6.8/flash_attn-2.8.3+cu130torch2.9-cp311-cp311-linux_x86_64.whl

# Install modelscope
RUN pip install --no-cache-dir modelscope

# Install Qwen3-TTS package
RUN git clone https://github.com/dffdeeq/Qwen3-TTS-streaming.git /app/qwen3_tts_streaming && \
    pip install -e /app/qwen3_tts_streaming

# Download Qwen tokenizer
RUN python /app/qwen/download.py



