import asyncio
import websockets
import json
import base64
import numpy as np
from faster_whisper import WhisperModel
import uuid
import warnings
warnings.filterwarnings("ignore")

print("ðŸ”„ Loading Faster-Whisper large-v3-turbo...")
device = "cuda" if torch.cuda.is_available() else "cpu"

# 4-8x FASTER than transformers pipeline
model = WhisperModel(
    "large-v3-turbo", 
    device=device, 
    compute_type="float16" if device == "cuda" else "int8"
)

print(f"âœ… Faster-Whisper ready on {device} (5x speedup, NO hallucinations)")

clients = {}

async def stt_handler(websocket):
    client_id = str(uuid.uuid4())[:8]
    clients[client_id] = {
        'ws': websocket, 
        'audio_buffer': [], 
        'last_time': 0,
        'speech_detected': False
    }
    print(f"âœ… LIVEKIT CONNECTED: {client_id}")
    
    try:
        await websocket.send(json.dumps({
            "type": "session.created", 
            "session_id": client_id
        }))
        await websocket.send(json.dumps({
            "type": "session.updated", 
            "session_id": client_id
        }))
        
        async for message in websocket:
            data = json.loads(message)
            msg_type = data.get('type')
            
            if msg_type == 'input_audio_buffer.append':
                item_id = data.get('item_id', str(uuid.uuid4())[:8])
                await handle_audio(client_id, item_id, data)
                
    except Exception as e:
        print(f"âŒ {client_id}: {e}")
    finally:
        clients.pop(client_id, None)

async def handle_audio(client_id, item_id, data):
    client = clients[client_id]
    
    # Decode PCM s16le â†’ float32
    audio_b64 = data['audio']
    audio_bytes = base64.b64decode(audio_b64)
    audio_np = np.frombuffer(audio_bytes, np.int16).astype(np.float32) / 32768.0
    
    client['audio_buffer'].extend(audio_np)
    now = asyncio.get_event_loop().time()
    
    # ðŸš€ REAL-TIME: 800ms chunks (vs your 4s+)
    buffer_sec = len(client['audio_buffer']) / 24000
    if buffer_sec >= 0.8 and (now - client['last_time'] > 1.2):
        await process_whisper(client_id, item_id)

async def process_whisper(client_id, item_id):
    client = clients[client_id]
    audio_array = np.array(client['audio_buffer'])
    client['audio_buffer'] = []
    client['last_time'] = asyncio.get_event_loop().time()
    
    try:
        duration = len(audio_array) / 24000
        print(f"ðŸ”Š Processing {duration:.1f}s...")
        
        # QUICK silence check
        if np.std(audio_array) < 0.015 or np.max(np.abs(audio_array)) < 0.08:
            print("â¸ï¸ Silence â†’ Skip")
            return
        
        # ðŸš€ FASTER-WHISPER: 4-8x faster + built-in VAD
        segments, info = model.transcribe(
            audio_array,
            language="ru",
            beam_size=1,              # Fastest
            vad_filter=True,          # Auto silence removal
            vad_parameters={
                "min_silence_duration_ms": 250,
                "speech_pad_ms": 200
            },
            condition_on_previous_text=False  # No hallucinations
        )
        
        # Combine segments
        transcript_parts = []
        for segment in segments:
            text = segment.text.strip()
            if text:
                transcript_parts.append(text)
        
        transcript = " ".join(transcript_parts).strip()
        
        # Filter garbage
        bad_phrases = ["Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ ÑÐ»ÐµÐ´ÑƒÐµÑ‚", "Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ", "ÑÐ»ÐµÐ´ÑƒÐµÑ‚", "ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° Ð¿Ñ€Ð¾ÑÐ»ÑƒÑˆÐ¸Ð²Ð°Ð½Ð¸Ðµ"]
        if (any(phrase in transcript.lower() for phrase in bad_phrases) or 
            len(transcript) < 2 or 
            len(transcript.split()) < 1):
            print("âŒ Filtered junk/low-quality")
            return
        
        print(f"âœ… '{transcript}' ({item_id}) [{duration:.1f}s]")
        
        # LiveKit speech events
        await client['ws'].send(json.dumps({
            "type": "input_audio_buffer.speech_started",
            "item_id": item_id, 
            "audio_start_ms": 0
        }))
        await asyncio.sleep(0.05)
        
        await client['ws'].send(json.dumps({
            "type": "input_audio_buffer.speech_stopped", 
            "item_id": item_id, 
            "audio_end_ms": int(duration * 1000)
        }))
        await asyncio.sleep(0.05)
        
        await client['ws'].send(json.dumps({
            "type": "conversation.item.input_audio_transcription.completed",
            "item_id": item_id,
            "transcript": transcript,
            "language": "ru",
            "confidence": 0.95  # faster-whisper confidence
        }))
        
    except Exception as e:
        print(f"âŒ Whisper error: {e}")

async def main():
    print("ðŸš€ ULTRA-FAST WHISPER STT (LiveKit WebSocket Server)")
    print("ðŸ“ˆ Expected: 800ms chunks â†’ <1s TOTAL latency")
    server = await websockets.serve(stt_handler, "0.0.0.0", 5000)
    await server.wait_closed()

if __name__ == '__main__':
    import torch
    asyncio.run(main())
