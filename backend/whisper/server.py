import asyncio
import websockets
import json
import base64
import numpy as np
from faster_whisper import WhisperModel
import uuid
import warnings
import torch
warnings.filterwarnings("ignore")

print("ğŸ”„ Loading Faster-Whisper large-v3-turbo (ANTI-HALLUCINATION)...")
device = "cuda" if torch.cuda.is_available() else "cpu"

# ğŸ›¡ï¸ ANTI-HALLUCINATION MODEL
model = WhisperModel(
    "large-v3-turbo", 
    device=device, 
    compute_type="float16" if device == "cuda" else "int8",
    download_root="/tmp/whisper_models"
)

print(f"âœ… Faster-Whisper ready on {device} - Ğ–Ğ•Ğ¡Ğ¢ĞšĞ˜Ğ™ ĞĞĞ¢Ğ˜-Ğ¨Ğ£Ğœ")

clients = {}
BAD_PATTERNS = [
    "ÑÑƒĞ±Ñ‚Ğ¸Ñ‚Ñ€Ñ‹", "dima", "torzok", "ÑĞµĞ¼ĞºĞ¸Ğ½", "ĞµĞ³Ğ¾Ñ€Ğ¾Ğ²Ğ°", "ÑĞµĞ¼Ñ‘Ğ½ĞºĞ¸Ğ½",
    "Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ğµ", "ÑĞ»ĞµĞ´ÑƒĞµÑ‚", "ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾ Ğ·Ğ°", "Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ñ‡Ğ¸Ğº", "Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¾Ñ€",
    "Ğ¾Ğ·Ğ²ÑƒÑ‡ĞºĞ°", "Ğ°Ğ²Ñ‚Ğ¾Ñ€", "ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¾Ñ€", "ÑÑ‚ÑƒĞ´Ğ¸Ñ", "ÑĞ¿Ğ¾Ğ½ÑĞ¾Ñ€"
]

async def stt_handler(websocket):
    client_id = str(uuid.uuid4())[:8]
    clients[client_id] = {
        'ws': websocket, 
        'audio_buffer': [], 
        'last_time': 0,
        'speech_energy': 0.0
    }
    print(f"âœ… LIVEKIT CONNECTED: {client_id}")
    
    try:
        await websocket.send(json.dumps({"type": "session.created", "session_id": client_id}))
        await websocket.send(json.dumps({"type": "session.updated", "session_id": client_id}))
        
        async for message in websocket:
            data = json.loads(message)
            if data.get('type') == 'input_audio_buffer.append':
                item_id = data.get('item_id', str(uuid.uuid4())[:8])
                await handle_audio(client_id, item_id, data)
                
    except Exception as e:
        print(f"âŒ {client_id}: {e}")
    finally:
        clients.pop(client_id, None)

async def handle_audio(client_id, item_id, data):
    client = clients[client_id]
    
    # Decode PCM â†’ float32
    audio_b64 = data['audio']
    audio_bytes = base64.b64decode(audio_b64)
    audio_np = np.frombuffer(audio_bytes, np.int16).astype(np.float32) / 32768.0
    
    client['audio_buffer'].extend(audio_np)
    now = asyncio.get_event_loop().time()
    
    # âš¡ Ğ Ğ•ĞĞ›-Ğ¢ĞĞ™Ğœ: 600-1200ms Ñ‡Ğ°Ğ½ĞºĞ¸
    buffer_sec = len(client['audio_buffer']) / 24000
    if buffer_sec >= 0.6 and (now - client['last_time'] > 1.0):
        await process_whisper(client_id, item_id)

async def process_whisper(client_id, item_id):
    client = clients[client_id]
    audio_array = np.array(client['audio_buffer'])
    client['audio_buffer'] = []
    client['last_time'] = asyncio.get_event_loop().time()
    
    duration = len(audio_array) / 24000
    
    # ğŸ”¥ Ğ–Ğ•Ğ¡Ğ¢ĞšĞ˜Ğ™ Ğ¤Ğ˜Ğ›Ğ¬Ğ¢Ğ  Ğ¨Ğ£ĞœĞ (ÑƒĞ±Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¢Ğ’/ÑÑƒĞ±Ñ‚Ğ¸Ñ‚Ñ€Ñ‹)
    energy = np.mean(audio_array**2)
    loudness = np.max(np.abs(audio_array))
    speech_frames = np.abs(np.convolve(audio_array, np.ones(512)/512, mode='valid'))
    speech_peak = np.max(speech_frames)
    
    # ğŸš« ĞĞ¢Ğ¡Ğ•Ğ’ Ğ¢Ğ’/Ğ¨Ğ£ĞœĞ
    if (energy < 0.008 or loudness < 0.12 or speech_peak < 0.15 or 
        duration < 0.4 or duration > 10.0):
        print(f"ğŸ“º Ğ¨Ğ£Ğœ (E:{energy:.4f} L:{loudness:.3f} P:{speech_peak:.3f}) â†’ Skip")
        return
    
    print(f"ğŸ”Š Processing {duration:.1f}s (E:{energy:.4f})")
    
    try:
        # ğŸ›¡ï¸ Ğ¡Ğ£ĞŸĞ•Ğ -STRICT VAD + ĞšĞĞĞ¢Ğ•ĞšĞ¡Ğ¢
        segments, info = model.transcribe(
            audio_array,
            language="ru",
            beam_size=1,
            vad_filter=True,
            vad_parameters={
                "speech_thresh": 0.8,           # 80% ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
                "min_speech_duration_ms": 600,  # ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 0.6Ñ Ñ€ĞµÑ‡Ğ¸
                "max_speech_duration_s": 12,
                "min_silence_duration_ms": 500,
                "speech_pad_ms": 100,
                "window_size_samples": 768
            },
            initial_prompt="Ğ Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€ Ğ¿Ğ¾ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ñƒ Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ½Ğ° Ğ¿Ñ€Ğ¸ĞµĞ¼ Ğº Ğ²Ñ€Ğ°Ñ‡Ñƒ",  # ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚!
            condition_on_previous_text=False
        )
        
        # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
        transcript_parts = []
        for segment in segments:
            text = segment.text.strip()
            if len(text) > 1:
                transcript_parts.append(text)
        
        transcript = " ".join(transcript_parts).strip()
        
        # ğŸ›¡ï¸ Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞ«Ğ™ ĞĞĞ¢Ğ˜-Ğ¥ĞĞ›Ğ›Ğ®Ğ¦Ğ˜ĞĞĞ¦Ğ˜ĞĞĞĞ«Ğ™ Ğ¤Ğ˜Ğ›Ğ¬Ğ¢Ğ 
        transcript_lower = transcript.lower()
        if (len(transcript) < 3 or 
            len(transcript.split()) < 1 or
            any(pattern in transcript_lower for pattern in BAD_PATTERNS)):
            print(f"âŒ FILTERED: '{transcript}'")
            return
        
        # âœ… ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞšĞĞ§Ğ•Ğ¡Ğ¢Ğ’Ğ (Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ğ±Ñ‹Ñ‚ÑŒ Ğ¾ÑĞ¼Ñ‹ÑĞ»ĞµĞ½Ğ½Ğ¾)
        word_count = len(transcript.split())
        if word_count > 20 or word_count < 1:  # Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ/ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ
            print(f"âŒ BAD LENGTH: {word_count} words")
            return
        
        print(f"âœ… '{transcript}' ({item_id}) [{duration:.1f}s]")
        
        # LiveKit ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ
        await client['ws'].send(json.dumps({
            "type": "input_audio_buffer.speech_started",
            "item_id": item_id, 
            "audio_start_ms": 0
        }))
        await asyncio.sleep(0.03)
        
        await client['ws'].send(json.dumps({
            "type": "input_audio_buffer.speech_stopped", 
            "item_id": item_id, 
            "audio_end_ms": int(duration * 1000)
        }))
        await asyncio.sleep(0.03)
        
        await client['ws'].send(json.dumps({
            "type": "conversation.item.input_audio_transcription.completed",
            "item_id": item_id,
            "transcript": transcript,
            "language": "ru",
            "confidence": float(info.language_probability) if info else 0.95
        }))
        
    except Exception as e:
        print(f"âŒ Whisper ERROR: {e}")

async def main():
    print("ğŸš€ ULTRA-FAST + ANTI-HALLUCINATION WHISPER STT")
    print("ğŸ“º Ğ¢Ğ’ ÑÑƒĞ±Ñ‚Ğ¸Ñ‚Ñ€Ñ‹/ÑˆÑƒĞ¼ = ĞĞ’Ğ¢ĞĞœĞĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ ĞĞ¢Ğ¡Ğ•Ğ’")
    print("âš¡ Latency: 0.6-1.2s Ñ‡Ğ°Ğ½ĞºĞ¸")
    server = await websockets.serve(stt_handler, "0.0.0.0", 5000)
    await server.wait_closed()

if __name__ == '__main__':
    asyncio.run(main())
